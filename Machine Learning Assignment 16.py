#!/usr/bin/env python
# coding: utf-8
1. In a linear equation, what is the difference between a dependent variable and an independent variable?
2. What is the concept of simple linear regression? Give a specific example.
3. In a linear regression, define the slope.

4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).

5. In linear regression, what are the conditions for a positive slope?

6. In linear regression, what are the conditions for a negative slope?

7. What is multiple linear regression and how does it work?

8. In multiple linear regression, define the number of squares due to error.

9. In multiple linear regression, define the number of squares due to regression.

10. In a regression equation, what is multicollinearity?

11. What is heteroskedasticity, and what does it mean?

12. Describe the concept of ridge regression.

13. Describe the concept of lasso regression.

14. What is polynomial regression and how does it work?

15. Describe the basis function.

16. Describe how logistic regression works.
Q.  1. In a linear equation, what is the difference between a dependent variable and an independent variable?
Ans: A linear equation in two variables can be described as a linear relationship between x and y, that is, two variables in which the value of one of them (usually y) depends on the value of the other one (usually x). In this case, x is the independent variable, and y depends on it, so y is called the dependent variable.Q. 2. What is the concept of simple linear regression? Give a specific example.
Ans: Linear regression quantifies the relationship between one or more predictor variable(s) and one outcome variable. ... For example, it can be used to quantify the relative impacts of age, gender, and diet (the predictor variables) on height (the outcome variable).

simple linear regression:  In simple linear Regression we only take the one predictor variable(s) and one outcome variable. EX: Calculate the height of person based on the weight. Q. 3. In a linear regression, define the slope.
Ans: The slope of a regression line (b) represents the rate of change in y as x changes. Because y is dependent on x, the slope describes the predicted values of y given x. ... The slope must be calculated before the y-intercept when using a linear regression, as the intercept is calculated using the slope.

The slope of a regression line is used with a t-statistic to test the significance of a linear relationship between x and y.


.

Q. 4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).
Ans: slop  = y2-y1/x2-x1
  = 2-2/2-3 = 0/-1 = 0 ###thus is constant—a horizontal line.Q.5  In linear regression, what are the conditions for a positive slope?

Ans:In summary, if the slope is positive, y increases as x increases, and the function runs "uphill" (going left to right).
Q. 6. In linear regression, what are the conditions for a negative slope?
Ans: If the slope is negative, y decreases as x increases and the function runs downhill. If the slope is zero, y does not change, thus is constant—a horizontal line.Q. 7. What is multiple linear regression and how does it work?
Ans: multiple linear regression: In multiple linear Regression we  take the one or more predictor variable(s) and one outcome variable. EX: Calculate the height of person based on the weight, age, gender, and diet. 

How does a multiple linear regression work?
Ans: 
Multiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. Every value of the independent variable x is associated with a value of the dependent variable y.
Q. 8. In multiple linear regression, define the number of squares due to error.
Ans :  the average squared difference between the estimated values and the actual value.

Q. 9. In multiple linear regression, define the number of squares due to regression.
Sol: Regression sum of squares (also known as the sum of squares due to regression or explained sum of squares) The regression sum of squares describes how well a regression model represents the modeled data. A higher regression sum of squares indicates that the model does not fit the data well.
Q. 10. In a regression equation, what is multicollinearity?
Sol: In regression, "multicollinearity" refers to predictors that are correlated with other predictors. Multicollinearity occurs when your model includes multiple factors that are correlated not just to your response variable, but also to each other. In other words, it results when you have factors that are a bit redundantQ.11 What is heteroskedasticity, and what does it mean?


SOL: In statistics, heteroskedasticity (or heteroscedasticity) happens when the standard errors of a variable, monitored over a specific amount of time, are non-constant.
With heteroskedasticity, the tell-tale sign upon visual inspection of the residual errors is that they will tend to fan out over time, as depicted in the image above.
Heteroskedasticity is a violation of the assumptions for linear regression modeling, and so it can impact the validity of econometric analysis or financial models like CAPM.

# Q. 12. Describe the concept of ridge regression.
# Ans: Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. This method performs L2 regularization. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large, this results in predicted values to be far away from the actual values.
Q. 13 Describe the concept of lasso regression.
Sol: Lasso regression is a regularization technique. It is used over regression methods for a more accurate prediction. This model uses shrinkage. Shrinkage is where data values are shrunk towards a central point as the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters)Q. 14. What is polynomial regression and how does it work?
Sol: Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x). ... The explanatory (independent) variables resulting from the polynomial expansion of the "baseline" variables are known as higher-degree terms.
Q. 15. Describe the basis function.

Sol :In mathematics, a basis function is an element of a particular basis for a function space. Every function in the function space can be represented as a linear combination of basis functions, just as every vector in a vector space can be represented as a linear combination of basis vectors.

Q.16 Describe how logistic regression works.
Logistic regression uses an equation as the representation, very much like linear regression. Input values (x) are combined linearly using weights or coefficient values (referred to as the Greek capital letter Beta) to predict an output value (y).
# In[ ]:




